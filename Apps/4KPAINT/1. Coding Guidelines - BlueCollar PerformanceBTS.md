# Writing FileMaker™ Database Software

# Code Development Guidelines, Design Patterns and Considerations, Development Environment Configuration, and Release Management


Updated: 12/8/25


Created By:


A


# Executive Overview

Nothing in this document is “cast in concrete” - it is all based on lessons learned from many years of doing FileMaker™ development, and what had evolved over those years, to enhance speed of development, reduction of errors, and just plain understanding of “what was I thinking” when the legacy product was developed.

This document is a guideline for future development. Existing code would not likely be conformant with the coding guidelines defined in this document, but can be useful characteristics to be applied, as applicable, to ongoing code maintenance.

The document contains a number of discrete sections.

- There is background on FileMaker internals, which can influence design decisions and is pertinent to understanding why some of the items in the technical details are what they are.
- The section on the supporting infrastructure, provides insights into why certain technical characteristics are more important that others in the supporting infrastructure.
- There are coding constructs such as naming conventions, with supporting rationale
- Numerous tips, tricks and traps are identified along with supporting design patterns that are improved coding practices.

## All About the FileMaker™ Product


# FileMaker™ Applicability

## Why FileMaker?

FileMaker, within its' single product environment and interface, includes all aspects of more traditional "full-stack" development environments, but contained in a single UX across all the features, providing significant increases in developer productivity.

For those people not familiar with traditional "full stack" development processes - all the pieces of the software product that make it complete - the major elements of data, data relationships, user interface, business logic, "glue ware" (how to "connect the pieces"), desktop deployment options (desktop, mobile, web), server deployments, backup, etc., are typically all disparate component pieces, each with a different development tool, user experience, and skill set.

Claris® FileMaker™ - ranked #1 (2021) in low code and workflow automation by Forester and G2 Crowdsourcing - even though it is over 30 years old, is evolving rapidly, adding new capabilities and performance enhancements at a rate that makes it hard to keep current with all the changes. At the same time, few legacy features ever get deprecated so older products continue to work unabated. Claris's parent company - Apple Computer - has exhibited far more interest to the product in recent years, which has accelerated the development into the leading product in the category.

FileMaker™, a 30+ year Apple® subsidiary, has a lot of perceived baggage and misconceptions about the platform, some based observations from legacy limitations, and others, based on poor implementations of solutions while retaining the FileMaker™ moniker. Many of these are valid concerns, but few, if any, are the result of FileMaker™ itself, and more accurately, a reflection on the developer's design decisions.

## Key Unique Value Propositions

Fulling integrated development environment:

- GUI screen layout editor
- Relational Database
- Relationship Modeling – super-set of an ER model
- Scripting Environment with auto-complete
- Robust calculation engine
- Robust API support; dataAPI, OData
- Integrated Web Viewer with Javascript support and bi-directional data access
- Developer built Custom functions
- Plugin Support

## Deployment Options

Development:

- Mac
- Windows

Client Environment

- Windows
- Mac
- iOS (FMGo)

Server Environment

- Windows
- Mac
- Linux
- FMCloud (AWS)

Deployment Hosting Models

- Single user, Mac, Windows, iOS
- Client Server

Licensing

Single User

Per Seat client-server

Concurrent user – per connection

Site License (25+ employees)

## 3rd Party Tool Support


FMPerception ($499/$249 annual) – fast analysis of everything in the Database Design Report (DDR) to assist in identifying errors, usage locations, etc.

FMComparison (free with FMPerception) – uses the XML export to compare one version with another, identifying anything and everything that has changed between versions.

FMLayoutLens (free with FMPerception) – copy > paste any layout to get a wireframe view of everything associated with a layout. Helpful in diagnosing problems in a layout.

OttoFMS / OTTODeploy (free) – allows external development efforts to be updated from a dev platform to a production environment automatically. Also includes tools to manage APIs

Inspector Pro 9 (free) – FMS 25+ only, provides similar functionality to FMPerception but not as effective as a dev tool (IMHO)

BaseElements ($499) – (not the plugin) competitor to Inspector Pro and FM Perception

FMDumpMigrator - “https://campsoftware.com/blog/?id=fmdump-migrator” – a tool to merge data tables, exporting to SQL and importing back to FM

ZippyCue - “https://zippycue.com” – new – not much information currently available.

DDRParser - “https://horneks.no/git-source-control-for-filemaker-meet-ddrparser” – limited current experience.....TBD

ChangeTracker - “https://makerlabs.abax.pro” – new, comprehensive from marketing materials, but unknown. Competes with DEVIN

XML-Export-Exploder - “https://github.com/bc-m/fm-xml-export-exploder”

Devin - “https://www.devin.fm” – Devops tool for FileMaker.

ProofGeist Labs  – ModLog. A web based tool (all data remains local), that uses versions of the XML export to identify every change to the code, when and by who.

ProofGeist – FMSvg – a tool, available on the web, to convert standard SVGs to FM syntax supporting colorization in states

ProofGeist – SimpleQ – a A lightweight queuing system built in FileMaker, making it easier to build applications that work together in a loosely-coupled fashion. Also designed to integrate with OttoFMS for receiving webhooks.

ProofGeist – ProofKit “proofkit.dev” - A collection of tools for FileMaker-aware JavaScript applications

Dracoventions and others TBD


## FileMaker™ the COMPANY

FileMaker™  - as of 2021 - has sold over 24 million copies and is available in 15 languages, has been consistently profitable for 80+ quarters (long term business viability), has over 3 million iOS FileMaker Go users, over 500 certified developers, 1400 partner organizations worldwide, 40 Platinum partners in the US, and over 50,000 members in the Claris Community support forum.

## DEVELOPMENT

FileMaker's Rapid Application / low code development’s time-to-value has historically been unparalleled. Newer AI driven development environments are starting to challenge that advantage, albeit it will far less depth in capabilities. A knowledgeable FM developer can create a very comprehensive customer business solution in days or weeks, where full-stack development takes months, with that requiring at least a half dozen different skill sets.

Full Stack development in a single product / single skill set environment:

- To do traditional full stack development, requires a range of skills in a variety of disparate tools, at a significant cost in both time and resource.

FileMaker™ is one of a very few - and the largest company in that space - that has a software development product that comprises the entire equivalent of a full stack development environment in a single product / developer UX and supporting multi-platform deployment. This single environment with common UX (User Experience) between all the aspects of full-stack development, but wholly within the FileMaker™ environment, makes for unparalleled developer productivity.

FileMaker™ has always supported the currently elusive "devops" (continuous delivery concepts). Traditional development models require off-line changes, and often complex re- deployment efforts. For most, devops is an elusive target:

- Live development - with the exception of field level schema elements locking all records for all users temporarily - everything about the solution can be edited live, while users are actively logged in. Care must be taken to ensure that the changes are not data destructive / corruptive and any modification that changes data, should be done after hours and with a current backup in place.
- Off-line development supported, with rapid data migration tools between revisions. Best for significant changes.
- With some needed architectural changes in the product, major productivity improvements can be gained, advancing the devops opportunities even more.

# FEATURES

FileMaker™ supports client-server, individual desktop, cloud based, and mobile for both iOS and Android platforms, as well as web deployment. With the exception of Android - which takes some work through a 3rd party product - the process is largely transparent to move from one to another deployment model.

On-premise and FileMaker™ Cloud are options for server based deployment. Multiple servers can be connected through external data sources. Web deployment also supports multiple slave machines, each supporting 200 additional users, to handle web traffic at scale. Web deployment can maintain security requirements as well.

The transition to a web-based, browser delivery model, can be accomplished in mere seconds. There are a few minor limitations of deploying through the web, mostly in how presentation / web rendering impacts layouts - but they can easily be designed around using existing tools. There are some minor design implications to delivering on a web page, but methods to make this work effectively on the web exist.

FileMaker web deployment affords significant performance advantages in many situations, and can overcome some less-than-ideal coding practices that impact performance.


## FEATURES

FileMaker Database (Draco Engine)


Proprietary Database engine (Draco) with unparalleled performance in a number of key areas. 30+ years of refinement. Near term, FileMaker™ will be adding MongoDB as a transparent option in the deployment/development model.

- Like OS400 or the PICK OS, all objects in FileMaker™ has a unique ID number (out of 64 trillion available), that is only used once. These makes evolving name changes through the system, transparent, as all the references to those named entities change dynamically, due to the unique ID is used system wide, "under the covers", reducing errors tremendously.
- Automatic generation of foreign keys, making creation of related elements, is foolproof and radically reduces orphan record issues. (although most novice developers are unaware of how to implement this or even more traditional techniques, and as a result, relationship issues and orphan records are all to common).
- Graphical User Interface (GUI) development with a comprehensive set of layout tools and capabilities. The robustness of the layout capabilities is best-of-class and produces rich, information dense UI possibilities.
- Pixel level object placement/ positioning, even when deployed thru the web.
- Event based objects, buttons, tab controls, sliders, popover, window types, and triggers
- Portal lists of related / dynamically filtered records
- Lists including sub-summary style data aggregation, directly supported
- Web Viewer in any window, with both support of standard web pages, as well as interactive JavaScript widgets supporting bi-directional data.
- Relationship Modeling - implemented as a superset of traditional ER diagrams, the model itself has significant computational power. However, design decisions in the model, can have a huge impact on performance.
- Integrated Development [coding] Environment
- Script workspace supporting a robust proprietary language with auto-complete
- Limited SQL support; has highly appropriate uses, but in most cases, produces a positive performance impact.
- Powerful calculation engine for script function arguments, with comprehensive auto- complete commands
- Custom functions; one can write their own functions.
- The robust built in language, is all auto-complete entry, significantly speeding up development, and with strong type-checking and syntax validation, many potential errors are eliminated.
- Security model - highly granular formula based security on any field, table, etc.
- Encryption-at-rest (optional / no cost)
- Encryption-in-transit - for both Client - Server and Web Access using the same SSL conduit
- JSON standards support in data sharing
- Bi-directional data API support
- Support for the top 8 relational databases, typically used to connect to existing systems and manipulate data directly in those systems using FileMaker
- oData and Data API, providing input and output for external access to FileMaker™ internals
- Applescript™ support, adding limited FileMaker™ command functionality to be accessible from AppleScript on the Mac platform. A number of FileMaker™ development tools leverage this capability on MacOS.

## DATA STRUCTURE CONSTRAINTS

8 terabytes per table, unlimited tables per file, unlimited files per solution.

Tested to 2,000 users, up to 10 helper webdirect servers supporting 500 users each

# SCOPE: TECHNICAL CONTENT

## FileMaker™ Limitations / TRAPs

- Bad design decisions do not scale well, and is quickly apparent - - - Good design decisions scale very well, with millions of records easily within scope.
- Legacy code constructs have advanced in current products, providing more efficient ways of implementing various features and capabilities. A lot of these legacy decisions, at scale, are bad design or design pattern decisions (see the above bullet)
- Transaction controls on data entry can be implemented programmatically. For 99% of all data entry, this is not an issue, but in some environments, transactions - commit all or none - is mandatory and requires some development work to implement. A new transaction model is now available, which make implementation of transaction based processing, far easier. There as other ways to accomplish this as well.
- Team development tools are virtually non-existent. Manual efforts need to be taken, as well as solid design approaches, to support multiple developers effectively. A lot of this has to do with the majority of deployed solutions supported by a single developer.
- Supporting team development requires establishing a sound development process outside of FileMaker, enhanced developer communications, and a code review/release process to be faithfully executed.
- Most of the performance limitations in FileMaker™ are based on novice user design decisions or the lure of the availability and use of quick and simple supported techniques. For no/ low code efforts, these techniques make development fast and easy. However, those simple techniques can severely impact performance at scale. FileMaker™ allows you to "be your own worst enemy" and create a number of implementations that really hurt performance and user perceptions. **Poor design can bring even the simplest solution to its' knees. **
- **NOTE: The most common reason for poor performance is associated with the display and usage of unstored calculations.**
- Often, data models continually build from a single inter-connected set of relationships. This "spider diagram" approach is a typical evolution of a product, but seriously counterproductive to overall performance and scalability. When any data changes, due to the computational aspects of the relationship model and unstored fields in various tables, EVERY table occurrence (an alias of a base table) that is related, is re-evaluated. This can be a serious performance problem.
- Good design practices can avoid this. A concept known as table occurrence groups (TOG), where aliased instances of base tables exist within their own group of relationships, independent of others, can radically reduce the computational demands of a spider diagram version of the same product.
- **There is no current concept of a master password**; an unscrupulous (or no longer accessible) developer with full access privileges can effectively change account permissions and lock everyone out of the system, with no recovery point, especially if encryption at rest has been implemented. I've recovered more than one solution where this occurred, never from malicious intent, but from circumstances where this scenario was not accounted for in security practices. Sound security policy can solve all but the most malicious intent. NOTE: the new privilege setting in  FMP 22.0.4 mitigates much of this problem by allowing a developer account to exist without access to credentials.
- Although SQL is a supported query language in addition to the native code, there are potential areas of performance impacts. If any record in the found set is currently user locked, eSQL will wait until that record is accessible to perform. This produces high variability in code execution times, therefore, eSQL should be judiciously applied if at all.

# Structural FileMaker

There are a number of unique key concepts about how FileMaker™ works, that are critical to understanding the program. Only some of the key concepts are described herein; those that would assist with understanding the unique attributes of how and why FileMaker™ operates and is constructed.

## Table Occurrences (TO):

Table occurrences - a set of aliases to source [base] tables - exist within the scope of the relationship diagram. A FileMaker™ relationship diagram is SIMILAR to a Entity Relationship diagram - a well known concept from traditional database design. BUT it is NOT quite the same. In FileMaker, these TOs are aliases to base tables; the actual database tables the information is stored in.

In FileMaker™ however, the relationship diagram’s table occurrences are integral to the way the program works.

The structural value of TOs is that they can be related together in such a way as to segregate the scope of data being acted on. Each relationship is, in effect, a query, so that referencing a field in a related table, will be filtered based on the validity of the relationship for a subset of records. Each TO has a unique name, but is in reality, the data in the base table.

This is in contrast to traditional Entity Relationship (ER) Diagrams, meant to be a representation of the understanding of how the data inter-relates. In most DB environments, this diagram is not even required, but is purely an aid to understanding.

There is a common **TRAP** that occurs in FileMaker™ development, where a developer creates a large, complex relationship graph, with at TOs connected. As each connection is, in effect, a query, edits of any data, trigger a reevaluation of all related TOs and any unstored field level calculations in those TOs. As one might imagine, this can be a very time consuming exercise.

A recommended construct (and there are others) is a concept known as Anchor-Buoy; a method of creating related TOs into a Table Occurrence Group (TOG), that only contains the relationships relevant to the current place within the product. This approach helps to minimize the cascading set of queries and calculations that occur in a non-TOG structured relationship model.

## Core Concept - **Context**:

Context is king in the FileMaker™ world. All actions take place based on the TO, whether it be a given screen layout, or a line of code. You MUST be in the right context (TO) for the program to operate, EVEN if you are referring to the correct field, if from a different TO. Context gives the program clearly segregated boundaries for code and layouts to operate within. This greatly simplifies working with the complexity of large relational structures.

Here is a simple scriot to assist in debugging this characteristic. Assign it to a button that is hidden for all non-dev accounts

**# List Fields on Layout ****- a 3 line script**

Set Variable [ $ListFields ; Value: GetFieldsOnLayout ( Get (LayoutName) ) ]

Set Variable [ $ListFields ; Value: Substitute ( $ListFields ; "," ; "¶" ) ]

Show Custom Dialog [ $ListFields ]

## Relationship Diagram (schema):

FileMaker's relationship graph looks like a traditional entity relationship diagram. However, the similarities end there. TOs (aliases to base/source tables) connect in a parent-child traditional database join structure called a relationship. In FileMaker, there relationships are, in effect, queries; they filter the content of the child table, based on the true conditions reflected in the relationship.

Compound relationships are supported, where the relationship between more than one field between parent and child, can filter that relationship.

Using global fields in the parent side of a relationship, one can dynamically change the filter conditions through a simple change of data content in the parent side global.

**FileMaker****™ ****also supports a unique relationship construct called** a "multi-line join" (not to be confused with multi-predicate, which is more than one field on the parent side of the relationship for the match condition). In this case, a list of values places in a single field on the parent side of a relationship, filters the child based on an OR condition - any of the list items matched against a single field on the child side. An example of this might be that you select a set of 3 states, matched against the state field in the child table, and all records for any of those 3 states are valid, true conditions from the relationship filter.

These results of the relationship filter can be displayed in a portal - a scrollable viewport into a child table from the context of the parent record. Alternatively, referring to a field in a child TO, as long as that child TO is related to the parent, will display the first record of the child table based on the sort order of the relationship. The portal allows a list of these records that are related to show from the context of the parent record.

## Layouts

Layouts are the equivalent of screens; each layout can be displayed as an individual screen on the computer. However, not all layouts are meant to be displayed. Many are created explicitly for the purpose of switching context - in order to access records within that given context.

Layouts can be presented in three forms.

- The form view displays one record per page with objects placed on the screen as the developer has defined.
- The list view displays all the records in the found set; the set of records matching a request for specific content.
- The table view displays all records in the found set in the form I wish spreadsheet like view. This view is seldom used my end-users as a developer has little control over the presentation / UI.

## Parts

Layouts have "parts" - screen/document sections that contain specific functional aspects.

- The primary part is the body - the typical location of the UI data elements.
- Sub-summary reporting provides a powerful and simple to implement reporting capability.
- In list view, additional part functionality can exist through the definition of sub-summary sections. These sub-summary sections provide for automatic aggregation of summation calculations, based on field level summary calculations. For instance, a calculation that sums a value, can be placed in a sub-summary section of a list, and when that list is sorted on a field that matched the sub-summary trigger, the sub-summary part appears, and sums only those records within each sort grouping.
- Headers and footers can be defined, as well as title headers (that only show on the first page of a report), and navigation headers that do not print on any report, but provide a place for user navigation elements to exist without impacting output. Note on FMGo (the iOS client), navigation headers also do not scale. Judicious application of navigation headers to support scaled screen displays is therefore possible.

## Data Objects

### Fields

- FileMaker™ can define fields to have Data Types of text, number, date, container (blob/ graphic/file), calculation (stored or unstored), and summary field data types. Each has it's own use.
- Fields may also be global, meaning that the content of the field in one record, is the same for ALL records in that table.

### User Interface [non-data] Objects

- Objects that provide user access to user initiated events or data presentation.
- Portals - a list window of data from another table occurrence
- Buttons/Button Bars - objects to click to initiate action; can also be used to present data
- Tab Controls / slide controls - a method of laying objects on a layout with affinity grouping.

## ESS (External SQL Sources)

ESS (External SQL [data] Sources, provides supported ODBC connectivity to a number of database products. These externally connected databases can be directly access as an integral part of the FileMaker™ environment, using internal code, or, in addition, traditional SQL code can be used for many operations.


| Data Sources | Windows Drivers | macOS Drivers | Linux | ESS requires<br>Actual Technology Adapter 1.5.0 |
| --- | --- | --- | --- | --- |
| Oracle Database 11g R2 | Oracle Database Client version 11g R2 | Actual Technologies, Oracle version 5.0.8 |  |  |
| Oracle Database 12c R1 | Oracle Database Client version 19.11.0.0.0 | Actual Technologies, Oracle version 5.0.8 | Oracle Database client version 12.2.0.1.0 |  |
| Oracle Database 12c R2 | Oracle Database Client version 19.11.0.0.0 | Actual Technologies, Oracle version 5.0.8 | Oracle Database client version 12.2.0.1.0 |  |
| Microsoft SQL Server 2014, 2016, 2017 | Microsoft SQL Server Native Client version 17.5.1.1 | Actual Technologies, MS SQL Server version 5.0.8 | MS SQL 17 (latest) |  |
| MySQL Community Server 5.7.21 | MySQL ODBC 8.0 Unicode Driver version 8.0.19 | Actual Technologies, Open Source Databases<br>version 5.0.8 | libmyodbc5.s o (pre-installed with FileMaker™ Server rpm) |  |
| For IBM i 7.3 (AS/400) | IBM iSeries Access ODBC driver 13.00.01.00 |  |  | X |
| IBM Db2 Version 11.1 | IBM DB2 ODBC Driver 10.05.800.381 |  |  | X |
| PostgreSQL 9.6.12 | PostgreSQL ODBC Driver (Unicode) 9.03.04.00 | Actual Technologies ODBC Driver for Open Source Databases 5.0.8 |  | X |


# Security

There is a matrix available that contains a checklist of conformance items for software against FIPS 140-2 and NIST 800. This section documents that security factors contained within FileMaker, but does NOT address, on a point-by point basis, the specific elements regarding compliance checklist alignment.

FileMaker™ has provided a solution-level user authorization and authentication security since version 7.

## Privilege Sets and Granular Security Controls

Authorizations can be extremely granular, with the security model allowing complex calculations on virtually any attribute or data in the system to be used as a constraint on data access at any level from individual fields to entire files. This can be used to provide selective access to data.

## Authentication

FileMaker™ provides for an authentication security setup that supports both individual users and policy groups.

**TRAP**: Authentication is far more rigorous in MacOS than on Windows. In Windows, 3rd party tools are available to reset any password in the system. Encryption-at-rest solves this security gap, as the expense of a business risk regarding privileged access management over-rides.


## External Authentication (EA) vs within FileMaker


Internal to a solution, you can set up users and allocate them to a privilege set, where that privilege set, defines a large number of user rights and privileges.

Situationally, you can possibly use external authentication to control user access - or the internal FileMaker account/password controls.

Inside a corporate environment, Azure / Active Directory, or other similar products, can provide a group policy, with users assigned to those groups.

- **TRICK**: In FM, the group becomes the user. This is especially useful for multiple files at a customer, where managing in native FM local authorization, which users have access to what application, done individually in multiple file security privilege sets, is an onerous process.

External authentication can also be provided through a cloud service, like Microsoft Azure, Google, or Amazon. Of the three, in the FM world, Azure (Active Directory) would be my current pick, although OAuth has recently come on the FileMaker™ scene. In Azure/AD, you assign user emails to a group name, and that group is what you set up in FM security, against a specific privilege set.

- **TRAP**: Azure is the only one of the 3 supported EA products that allows group names, not individuals. Using Google or Amazon, requires setting up the user in both the EA product AND in FM - a redundant effort that gains little and costs a lot.

## Encryption-in-transit (SSL)

An SSL is a mandatory aspect of baseline security today. FMS requires it to operate. The SSL process, has historically been painful, with inconsistent terms, file names and process, none of which are familiar to the typical IT person, much less a consumer. Claris has done a relatively good job, at least from the FM side, on making the process as easy as possible. The pitfalls are remain within the SSL vendors, and their processes for getting access, and what name means what in different SSL vendor's terminology.

The installed SSL covers all external access to the server; FileMaker™ client software, web access, administrative API, and Data API.

## Encryption at Rest (DBs)

Encryption At Rest (EAR), is a feature that makes the theft of the entire solution useless as without the passwords, no access to the content of the database exists.

- **TRAP**: IF a malicious - or otherwise - full access user were to not provide their credentials for at least one Full Access account, and for whatever reason, did not return to the job, no one would be able to access the system AND with EAR turned on, none of the various password reset tools will be functional.

## Encryption (fields)

Field level calculations can invoke encryption/decryption at the field level.

There is also protected field presentation object, that obfuscates the content of a field at both entry and display.

## File Access Controls

Files are connected using External File Access. The permissions granted through the file security model, can have an additional control invokes using File Access Security. Not commonly used, File Access Controls allow granular controls on what aspects of external file access is available.

## Security Model

**TRAP**: Obscure and obtuse, the security model is a powerful tool. The obscurity poses issues during debugging, as event occur that cannot be explained in the code, until you recall that the security mode is in use.

NOTE: Although Claris indicates that FileMaker™ is NIST 140-2 complaint, they no longer certify the product as such, citing the constant evolution of features that are being introduced at a rate faster than the certification process, making the effort unfeasible.

# Optimizations/Modernization

## Data Size and Data Segregation

The value proposition: The greater number of records, the more work the code does to to show selective information. FINDS and SORTS are both common techniques that are heavily impacted based on the number of records. Reducing that record count, ups performance.

Archiving (millions of records): data sets can be large, with lots of historical data. Moving unused or seldom referenced data to an external file or another table, can radically increase performance by reducing the production data set that needs to be acted on.

Data currency requirements needs to be developed, so that various tables with years of legacy data, can be segregated out to separate tables as archives. The data would remain available, with some code effort to provide access to the archived data if required.

The work effort: This effort would vary, based on the access needs for the legacy data. The approach of creating a new archive table and moving the data based on some selective criteria, can be done within a few hours per table, dependent on the size.

Unstored Calculations and Performance Implications

The value proposition: performance, performance, performance. Unstored calculated fields - seldom necessary, but often implemented due to ease of creation, simplicity, and data quality - bog down performance

Unstored calculations have value, but judicious use of these is imperative to performance. It would be theoretically ideal to not have any unstored calculation fields, but in many cases, the effort to make this occur, exceeds the value.

However unstored field level calculations  are a red flag relative to performance.

- Example: As a result of a code review and code refinement process, one SQL script step was taking over 400 seconds (almost 7 minutes) to execute, as it was operating against an unstored calculation.
- Correcting this script step to use a stored calculation, reduced the time in 1/10th of a second, a ~4,000 times improvement in performance.

The work effort: The solution may be in changing how the field acquires its' data, or in how scripts and layouts present this data, or a combination of both. This will be an evolutionary process on a per-instance basis. The effort will be on-going, but should be #1 priority with the optimizations activity

## Refactoring - Performance, Quality and Maintainability

The value proposition: performance, quality, maintainability. Using standard design patterns consistently make code more readable, maintainable, and performant.

This is a complex topic with a nearly infinite set of variables. In coding, there is almost always more than one way to do something. As an overarching aspect, I can't emphasize enough how standard naming conventions would improve developer performance. This is covered in detail in the section on naming conventions, including rationale.

- Scripts - using better design patterns in scripts will radically improve quality, performance, and gains to developer best practices. There are many of these, and the quantity is outside the scope of this document.

#### *Examples are provided in the Optimizations/Modernizations section.*

Again, in the code review/fix process, refactoring of the code (not including the unstored calc issue that provided the 4,000x performance of that one aspect) resulted in a >3 times improvement in total script execution speed.....not a bug fix, per se, as the code worked before.....just a better design pattern refactored into existing code.

*The work effort: This is not a one-and-done exercise. This is an ongoing evolutionary change of product improvements that benefit both users and developers. If done correctly from the beginning, this refactoring would not be necessary. *

## Navigation

#### The value proposition: Removing Deployment Option Limitations

Many existing products makes extensive use of traditional menus and drop-down list in those menus. Some of the deployment options for FileMaker™ such as FMGo on the iPads and WebDirect through a web browser, do not support menus. Therefore, in order to implement the capabilities of these menus it has to be done with a different method, ideally with screen based navigation elements.

The advantage of approaching this from a different perspective, provides a very modular, reusable tool that is applicable not only to the navigation menu systems how much but to data selection in fields.

The work effort: A sample of a proposed alternative method to perform this function has been provided to Brett, using a window with a scrollable menu. This approach is both universally applicable to all platforms, and flexible in content, providing lots of alternative uses.

## Refactoring User Interface - Performance and User Experience/Interactions

The value proposition: Data load and user performance, improved user productivity

Due to a number of conditions exist with and layouts, performance in opening layouts is often sluggish. There are simple techniques that would radically increase both the users perception, and the real data load performance with very little code effort and no impact on the data.

- User Interactions - layouts often take a lot of time to load, giving the user a perception of poor performance and consuming valuable time. Adding a LOADING window assuages some of the user concerns by providing feedback of activity rather than unresponsive software. In addition, unstored calculations on layouts - especially list views, are big performance hits. By changing workflow between screen, adding intermediary screens, using different views, and exposing unstored calc fields on demand, instead of all the time, can provide big gains.
- User Interface - in effective software, especially around workflow processes, presenting the right data at the right time, requiring the lowest cognitive load to assimilate that content, is essential. This process, known as Performer Centric Design, encompasses how to make the user more productive

As many legacy UI/UX environments have been established over a long period of time, and users are familiar with the layouts, this change may be one of the most disruptive to the users, but provides great benefit in operational efficiency

The work effort: Refactoring layouts, especially with high information density on a layout, may require a significant amount of rework. This is another place, where a design pattern - this one based on the desired User Experience (UX) needs to be worked out over time, then applied. Examples of this approach can be provided when the time comes.

Once a complete triage on the main issues identified in the system, this would be a candidate activity to tackle.

## UUID vs Serialized Fields

The value proposition: Data consolidation and data sharing, while retaining a guaranteed unique identifier for those records.

Serialized fields are used for primary and foreign keys - the data elements that connects parent records with child records - e.g. one shop order (parent) with N number of operations (children).

An issue with typical serialized fields, is that serial numbers can be the same on more than one database. This is particularly important if the data from more than one database needs to be consolidated. When combining data, duplicate primary keys (serials) cause major havoc to the database, and it does not know what is related to what, when more than one serial key of the same value exists.

UUIDs - Universally Unique IDentifiers - are mathematically generated unique alpha-numeric codes which include an encoded time to the microsecond. Combined with the additional math in the generation process, the probability of a duplicate UUID occurring is almost infinite.

However, this does not solve the issue of historical data. That transformation of legacy data is far more complex.

The primary key relates to N number of child records based on that value. All child records would need to be changed to match in order to maintain referential integrity. A method using a temporary duplicate of those keys, scripted to update that in all 261 tables, followed by a replacement of the existing keys with a newly generated one, would be performed.

Natural Keys:

If there are any places in code where the data (not UI) relationship keys are based on user data, these would need to be considered first, as this code is brittle and risks data quality/validity. Primary data relationships are always based on system level keys, whereas UI elements often use natural keys for presentation.

The work effort: Swapping natural keys for system level – and NEVER presenting those keys to the users, makes for a better design. Primary keys should be set to UUID.

For the legacy data, a project needs to be started to make that transformation.

## Performance Aspects


Performance Tuning

### Design Patterns

Writing FileMaker™ solutions is quite easy; writing performant, scalable FileMaker™ solutions in another matter altogether. There are a lot of factors that contribute to performance hits. Removing those impediments can result in a highly scalable system. Although there are performance tips throughout this document, there are some more general ones that are useful. In addition, there are numerous design patterns; best practice approaches refined over years of evolution.

### Code Structure - Refactoring

### Design Pattern: Example Code Structure Change - FIND

In legacy FileMaker™ code, there is a construct for executing a FIND for requested data. The code - used in a 9 places in this script - looks like this:

PERFORM FIND [restore] or CONSTRAIN FIND [restore]

All the logic is in the "restore" option, which is buried in a dialog and not visible in the script directly. This legacy construct has a number of issues regarding UX, but remains available to use in order to support legacy code bases.

We rewrote the code in this form:

ENTER FIND MODE

SET FIELD ( <TheFieldToSearch> ; <TheValueToSearchFor> )

PERFORM FIND [ ]

In this functionally identical, but more verbose structure, the search conditions were highly visible - and identified that the ValueToSearchFor was the wrong thing. *One can now immediately see the problem once this refactored code provided visibility. *

#### Design Pattern: Layout Switches

On entering a layout, typically you want to constrain the records shown on that layout to the set that is appropriate for the task at hand. However, on initial entry into that layout, the layout loads ALL records in that table, before processing any request to limit or constrain what is being displayed.

A typical legacy design pattern looks like this:

Allow User Abort [ Off ]

Set Error Capture [ On ]

Go to Layout [ “CPOREQ Utility” (CPOREQ) ]

Show All Records

Show Omitted Only

New Record/Request

Set Field [ CpoReqSTATUS::Status; "New" ]

"New" Set Field [ CPOREQ::StatusCurrent; "New" ] "New"

Go to Layout [ “Purchase Request” (CPOREQ) ]


By changing the design pattern of this code block, one can gain substantial performance improvements. The user sees the new layout first, then the layout populates.

Before line 3

Enter FIND mode [ off ]

Replace lines 4 & 5 with

Set field ( CPOREQ Utility::a__pk ; "=" ) //empty primary key, so no records

returned

Perform Find [ ]

Design Pattern: Example Code Structure Change - LOOPS

The Legacy pseudo Code:

- Gather a list of items
- Identify the number of items (for the loop count)
- Start the loop through the records to search
- Increment the loop counter
- Grab the incremental count item in the list
- perform a find for that one item (using that obscure legacy FIND construct resolved above)
- add (concatenate) that item to a new list
- End the loop once all items have been found.

The loop has to repeat a FIND, traversing all the records, one time for every individual item in the list, traversing all the records to identify the one matching record, and then repeat.

The refactored pseudo code:

Gather a list of items

Identify the number of items (for the loop count)

#---------------------------

Enter FIND MODE

#---------------------------

Start the loop through the records to search

Increment the loop counter

Grab the incremental count item in the list

SET FIELD for that item from the list

Add a new FIND request record

End the loop once all items have been found.

#---------------------------

PERFORM FIND

#---------------------------


In this refactored structure, instead of the FIND having to traverse all the records N times, it only does it once. FINDS in FileMaker™ are extremely fast, but the larger the data set, the longer it takes and the legacy code repeated this over and over. This refactoring changed from doing this FIND once for each item, to a single find resulting in all items in one step. So for 5 items, this code would be 5x faster.

#### Design Pattern: Fields

Unstored calculations - use judiciously and try to avoid if at all possible. In list views, unstored calculated fields can kill performance.

#### Design Pattern: Landing screen

It is useful to present to the user, something/anything ASAP in a solution, so they know something is happening. Using a splash screen, based on a global table (no data to load) is a great way to start, and can be the universal launch point for user interactions with the system.

#### Design Pattern: Loading Data

ALWAYS restrict initial data display to the minimum set of data required.

In other words, don't go to a layout and display every invoice; only those that are open, are relevant initially.

- **TRICK**: In General, ALWAYS enter find mode before switching to another PRESENTATION layout, execute the find, then display that subset of the total data (if possible). This also provides a trigger to allow using the Get (WindowMode) to display a LOADING dialog, providing the user feedback that something is happening.
- **TIP**: Opening a FLOATING window type with a web viewer and an animated image (with a .1 second delay to allow the web viewer to load and start), or even just a text message, then selecting the background window, can provide useful user feedback as to the fact that something is going on, be patient until the loading window closes.

#### Design Pattern: Relationship Matches

As FM's relationship model, is, in effect, a defined set of queries, there are some really effective performance aspects that come to play.

- **TRAP**: Portal filtering is an easy method of constraining content in a portal. However, portal filters act POST data load, so that all the related data must load to the portal first. The filter is applied AFTER the data loads. According to the record count, this can be a big performance issue.
- **TIP**: Portals - at least for large data sets - should be filtered through a relationship, NOT from a portal filter. set of matching data content written to a global parent field that is related to the child content, runs BEFORE the portal is loaded, so that the data set is far smaller. Using a portal filter as a secondary filter, is fine, assuming the initial filter has greatly reduced the amount of records to be displayed in the portal.
- **TIP**: This is a case where a TOG used for presentation, is a powerful construct, in that it affords consistent views of data with little effort.

#### Design Pattern: TOGs and Anchor-Buoy (or other TOG breakouts).

- **TRAP**: With all the benefits of the unique FileMaker™ relationship model, there is a downside (ok, more than one :-) ). The more relationships defined, the larger the performance hit is. When anything changes in any record, ALL relationship across ALL related tables reevaluate AND all fields impacted as a result, also recalculate. This can be a big performance impact. TOGs restrict that to the subset of TOs that are within the TOG, greatly enhancing performance.
- **TRAP**: This also implies that the often deployed Selector-Connector design pattern poses problem for performance, as the connector removes the independence of the TO Groups. TIP: There is a way to use a refinement to Selector (sans connector) to get to the same result and even faster.
- See GTTR on Source Table Across TOGs

#### Design Pattern: Summary ListOf

As of FM14, the new summary calc of ListOf was defined. This internal command allows the fastest possible way to produce a list of the content of a given field within a table. The summary is dynamic to the found set (which is also the subset in a sub-summary section, for that sub- summaries effective found set).

A good use for this list function, is to quickly gather the IDs for a group of records, write then into a variable, then write that variable into a field used in a relationship. In the following section, a good use case for this will be defined.

#### Design Pattern: GTRR on source table across TOGs

Unstored Record IDs: there is an advanced concept for pulling together found sets of data that uses a unique characteristic of FileMaker. As every object in FileMaker™ has one of 64 trillion unique IDs (and 64 trillion per table as well), the record based IDs are contained dynamically in memory. Instead of traversing a group of records to gather a field used to segregate data, using the in-memory unstored ID is as much as 20,000 times faster.

Using a separate TOG, where a global field is matched against a child table for a given field, one can set the global value in the parent, do a GTRR to the child then display the results in a completely different TO, provided they are both based on the same source table.

Why would you do that? (And no, this is not always the best design pattern option).

- **TRICK**: FM assigns every object, every record, etc. a unique and immutable ID value. For records, it can be retrieved with a Get (RecordID), a number that is unique to that record and will NEVER be reused ever again in that table’s records. The limits on this assignment are 64 trillion unique IDs.

IF you have 2 fields in each table - a STORED Get (RecordID) and an UNSTORED Get

( RecordID) - both calculated fields, the UNSTORED recordID is, by definition, UNSTORED, so it is in memory. Using the Summary ListOf against the unstored recordID will return a list of unique recordIDs for the found set, and do it extremely quickly, even over a WAN, as it does not have to traverse all the records, but can gather the information from memory.

NOTE: This is unique to the RecordID function; no other unstored field will provide the performance gain.

Writing the result of that ListOf summary fields, into a global variable, matched against the STORED RecordID field in the same table (unstored values cannot be used in relationships, so neither the summary calc or the unstored record ID are in play in the relationship model), will filter the list to the matching records.

Then a GTRR from the parent to the child, followed by a display in layout, some other layout matching the presentation needs but from the same source table, will display that found set.

Why would you do this, as the FIND itself, gets you to the list of records that you need?

A FOUND SET of records is unique to the CURRENT WINDOW (not the current layout within the window). As such, techniques must be applied if you wish to execute a FIND  in one window and display it in another.

The issue is NOT in displaying a portal from a single parent, but displaying the portal from a group of parent records. Somehow, you need to gather the list of parent records, and put them into the relationship to display the related child records in the portal.

A List Of, or a loop, used to gather a list of records, can be slow, especially over a WAN, dependent on what data fields you are attempting to gather.

Gathering a list of something that is different from one time to another, requires additional relationships, and fields. If the Get (RecordID) fields are both in each table, they are uniformly available for use, and the same in every table. On top of that, a single parent global match field can store any set of recordIDs but the only child TO that will have data, is the ones that match the unique recordIDs.

A further implication is you can grab a list of recordIDs from multiple child table FINDs, place them ALL into one global match field, and display portals for each child that will have all the FOUND records for each child. There is no overlap of RecordID #s.

CRITICAL NOTE: The RecordID is NOT a replacement for a UUID as a key field, as there are scenarios where the recordID is recreated, like in copying the application and removing existing data. As a result, **do NOT treat recordIDs are permanent, but just as static for transactions. **

### Performance: Summary vs calcs - when to use and why

Each summary field calc has an equivalent calculation function. The difference, is that summary fields work within the context of the existing found set in a given table, vs the equivalent calculation works across relationships (for multiple records) or across fields (in a table’s single record).


Summary calcs operate WITHIN a given table, allowing match to span the records within that table. Each of these commands are available in a field level calculation or a script, performing the identical function, BUT ACROSS A RELATIONSHIP. This is often used for de-normalization of data between tables, where it is advantageous to have a field from a related table in another table, for things like finds within child records.

In both cases, the resultant calc is unstored.

Also each of these commands can be used IN A SINGLE RECORD within one table, across a set of fields.


##### There are use cases for both, to be defined later......

Performance: Insert calc result vs Set Variable

In gathering a list, say in a loop, it is often useful to place the results in a variable.

You can use a SET Variable & $varName to continually append values. This is fine, especially for small data sets.

However, if the data set is more than a few dozen records, you start to see significant performance gains in using ......

INSERT CALCULATED RESULTS (replace). In tables of thousands of records, the performance gain is exponential.

- TRAP: The SET VARIABLE approach requires that you concatenate the existing variable to the itself to retain existing values. The INSERT CALCULATED RESULT if replace is set to off, does not, but still requires a concatenated carriage return to support multiple lines of values.
- TRICK: SET VARIABLE increases the time with each iteration, for each iteration. Insert Calculated Result used the same time for each iteration, without growing as more records are added.

#### Design Pattern: FINDs in related tables.

Not a performance issue, but a technical one: finds using fields from related tables (layout based on parent context), will find ALL the records from the related table that meet the FIND request. This is situationally ok, but has a potential **TRAP**.

- **TRAP**: in a related data set, displaying a field on a layout, knowing that the content of that field is the first record of the related table based on the sort of the relationship, a FIND against that field will search records other than the one being displayed. As a result, the found set is often not what was expected. A record gets returned, but what displays are parents that may not have that content in the first related record for that field that was searched.
- e,g, you do a FIND in a related date field displayed on a layout. The FIND works, and it found all related records for that date. However, as you are only displaying the first record of the related table, it appears that the FIND did not return what you were expecting.
- **TRICK**: Gets messy; There are a couple work-arounds, one using GTRR twice (find, go to parent, then a GTRR back to child, but it is **tricky**).

#### Design Pattern: Cascading FINDS:

Equivalent to the concept of a B-Tree search, FINDS can sometimes benefit from a cascading mul**TIP**le FIND block technique, where you narrow the data to the smallest set first, then refine the search from there.

Performance: Get (FoundCount) unstored

- **TRICK**: Definitely in the realm of performance and a great **TRICK**. An UNSTORED Get (FoundCount) calculation in a child table will return the count of the found set, even if that found set is discovered through a relationship. SO, placing the related Get (FoundCount) on a parent layout, will reflect the count within the portal of that same child table.
- **TRAP**: A portal filter will NOT change the found set count, but instead, display the pre-filtered child record count. Another reason to use relationship filters for portals and not in portal filter.....

#### Design Pattern: Adding portal records (false)

This one is all about context. IF you have a portal and want to add records, the code is typically messy, having to navigate to a layout based on the child table, do the data edits, and return.

There is an easier way :-)

- Create a second portal on the parent layout, using the same TO as the display portal of related records.
- Make that portal one row tall.
- Set the portal filter to "false" - undocumented, but has existed forever. A portal set to false, will not display record data.
- Imperative: the relationship must be set to create records through relationships for the child table.

In that one line portal, place a button that scripts adding any data to any field in the child table, a popover button with more fields, a field itself, ..... anything that adds content to the child record, will, when entered, automatically create the child record. It will immediately show up in the larger data portal.

It would be prudent to hide everything on a portal row when the primary key does not exist - keeps the interface clean.

It also might be prudent to set the sort on the data portal to the most recent timestamp on the top, so that the user expectation of a record added would show at the top of the list, not at the bottom, which may be below the visible set of records and require scrolling to see it.

#### Design Pattern: Database Schema

Wide vs narrow tables; especially in WAN connections, wide tables are a performance problem. As FINDS and SORTS require that the entire found set be moved to the local client, the more fields of data, the more volume of data that has to move. Narrow tables are preferred.

#### Design Pattern: Additional Programming Language Support

The built in ExecuteSQL can be a boon or a bust; the non-contextual nature of SQL often makes things work better, however, according to how the SQL statements are structure, and what they are acting on, can be a big performance hit.

Javascript is supported in a web viewer, with bi-directional access to FileMaker™ data. This affords opportunities to leverage the vast array of Javascript solutions available.

#### Design Pattern: Server Side Execution Options

Web Direct vs any FM client: web direct is, in effect, running as a terminal to the server, so no data outside what is being displayed on the screens, is moving over the net. This affords substantial performance benefits. In additional, FMS supports companion web servers, offloading the Web Server functionality to the companion machines, 100 per web server machine.

Terminal Server: Like Web Direct, Terminal Server runs everything directly at the server, so data movement speeds are not network dependent, but server hardware dependent.

PSoS (Perform Script On Server script step): FileMaker™ server supports server side scripts, which, in many cases, provides substantial performance benefits. PSoS scripts have a number of development patterns that must be observed, all of which are specific to PSoS running as a separate headless (no display) user. This has implications to data passing and error trapping that must be accounted for. However, the speed benefit can be substantial. In one recent test, a scripted process that was taking just over 9 minutes to run on a client, when moved to PSoS, run in just over 2 seconds.

#### PSoS and Scheduled Server side script rules

#### FileMaker PSoS rules

It’s a unique user (fmse) - not the user initiating the script

Globals, being user/session specific, are not passed in

It does not know the layout context by default - set it in script

It does not have the found set by default - FIND it in script

Any script step that requires user interaction will hang

Script parameters (in) and exit script / Get (ScriptResult) (out) can be used to pass info back and forth

There is no debugger in server side scripts.

An error without graceful recovery will hang the script

e.g. In a loop, GoToRecord (Next;Exit after last) will hang. Instead, use an increment counter in the loop, and an Exit Loop if (increment ≥ recordCount)

Scheduled scripts have the same constraints.


#### Design Pattern: Virtual Lists

Virtual Lists: these are lists of data, assembled through code, and placed in memory, using a technique to display those records in a list view. The technique is powerful, and highly performant. The one downside, is because the list is maintained strictly in memory, once one leaves the list, all that transient data goes away.

We have a great model to easily implement a virtual list, available on request.

#### Design Pattern: Portal Pick Lists

Portal pick lists provide significant functional gains in both the user experience, as well as the effort in the relationship diagram. The opening of a portal pick list can be dynamically populated under script control, from any data elements, making for a very flexible and modular approach to selections. This can be effectively used in data entry, or menu navigation systems, are among a few of the ways to apply this.

# Hardware

FileMaker™ performance is dependent on a number of system hardware factors. There is a priority to those factors, where performance gains can be best attained.

It should be noted, however, that even the best performant hardware configurations cannot overcome bad software design conditions.

Network Performance: As typical client-server FileMaker™ deployments use a desktop client, AND as code typically is run on the Client and record in the found set of data gets downloaded to the client. Network speed is therefore, a key performance factor, given traditional, normal FileMaker™ design.

It should be noted that there are methods, such as Perform-Script-on-Server, that can negate much of the network bottleneck by creating the subset of data on the server, prior to it being displayed on the client desktop.

Disk IOPS (Input Output Per Second): (aka data transfer rate) FileMaker, like any database, is constantly reading the writing data to disk. The faster this operation is, the more performant the database is.

- Most legacy computers use a disk interface known as SATA, the latest version being III (SATA III), which provides an data transfer rate if 6 Mb/s (6 Megabits per Second). Paired with traditional rotating media disk drives, which are about 50x SLOWER than SATA III, has been the norm for over a decade.
- With the advent of SSDs (Solid State Disks), the latency around rotating media sectors and head positioning, has gone away. A typical SATA III SSD can nearly saturate a single SATA III interface. (There is also a server disk interface called SAS, which provides some parallelization, but is still tied to rotating media protocols).
- The command set to read/write data over a SATA III interface is AHCI (Automated Host Control Interface), which reassembles in code, the track and sectors pulled together so as to make a sequential data file.
- SSDs did not need that, as they have no heads or tracks/sectors, only memory locations.
- So NMVe (Non Volatile Memory enhanced) was created, removing the track/sector requirement of rotating media.
- But now SATA III was not even close to supporting the newly capable data rate of SSDs using NVMe command protocols. So the disk interface changed over to PCIe, a well-established multi-channel bus interface I/O specification.
- The pairing of an NVMe aware SSD, with PCIe, allows a data transfer rate of around 32 Mb/s, over 5x the performance of the best that SATA III can offer.

Enter RAID - Redundant Array of Independent Disks. There are a number of RAID levels, each providing different data protection and performance tradeoffs, but suffice it to say that with any of the disk technologies, there is a RAID configuration that can bump up performance substantially.

FileMaker™ server hardware would best be served with NVMe based SSDs configured in a RAID.

Server Performance: More true today than at any time in the FileMaker™ past, FileMaker™ Server can now relatively effectively use additional processor cores for many operations, and more are being added with each new release.

Higher processor clock rates work for everything; more cores are where the future of server performance lies.

# oData / Data API implications

FileMaker™ has historically included limited API functionality in requesting and gathering data from outside products using basic API commands like cURL.

The recent releases of FileMaker™ have incorporated a far more advanced API functionality, opening up great possibilities. This new Data API functionality has also ended up deprecating the Custom Web Publishing API in FileMaker™ that supported PHP front ends, with this far more robust and flexible method

Since the advent of this more capable API, a few products have come to market, that exploit the capabilities of that API well beyond the basics of passing data.

One of the key advantages of these alternative client deployment options and the associated segmentation of processing between client and server, is the Data API can support thousands of users - and NOT consume a user license.

#### FMBetterForms

This product uses custom Javascript objects and widgets, Javascript libraries and JSON data structures to interact with FileMaker. This product is around 3 years old, and has a solid following, especially among the Javascript literate.

It is both fast and capable, and can scale to far more users that the thick client FileMaker™ desktop product.

#### Web Direct

Web direct has been in FileMaker™ since version 13. It provides a translation layer between FileMaker™ layouts and web pages, with near complete fidelity. There are very few, and all insignificant, limitations in Web Direct deployments. There are major benefits to be had in using Web Direct.

The time to deploy, from a FileMaker™ (not network or network security basis) for an existing FileMaker™ product, is under 60 seconds - literally, it is opening dialog, setting a checkbox and a couple conditions, and clicking OK.

Web Direct can then be accessed from any browser. Almost everything works without issue from web Direct (WebD). There are a number of advantages to Web Direct as well. In particular, as Web Direct, like a terminal server deployment model, executes completely on the server, the performance is exceptional. There are no data load times over the net and only the screen content is being transmitted. Performance is typically outstanding.

#### Terminal Server Option

Any terminal server product - Microsoft Terminal Server, Citrix, Parallels, TSPlus, etc., - can provide a windows session to a remote user. This approach, like Web Direct, has the advantage of only moving a screen full of data, not the entire data set, to display on a layout. The terminal server can be co-located with the FMS machine, and may have very high speed interconnections, further enhancing performance.

The downside is that terminal servers are notorious resource hogs, requiring a lot of server horsepower to provide these services to users.

#### Web Viewer

FileMaker, for over a decade, has allowed the embedding of a web viewer on a layout. This web viewer allows the display of web pages. It also allows the embedding of Javascript libraries, of which there are literally thousands of them freely available.

The current version of FileMaker™ allows bi-directional data sharing with these web viewer embedded javascript objects. This provides for many complex javascript objects to be used for display of information, and now, data input.

For instance, there are massive libraries of chart types freely available for Javascript, that can be placed on a FileMaker™ layout and feed FileMaker™ data, to display complex charts and graphs.


# Development Aspects


## Development Process

### Software Development Life Cycle (SDLC)

#### Release Management - Code Reviews, Code Development and Maintenance

(Note: this is NOT definitive, but open for discussion)

Implement a simple, fast, release management process for code, including code reviews and test criteria. (team efforts have some overhead, but afford great gains in overall development effectivity, once a SDLC (Systems Development Life Cycle) is established. In the FM world, this SDLC is VERY lightweight, compared to traditional development, but product quality and shared learning will all benefit.)

Process Steps

- Issue root cause analysis
- Debug
- unit test
- code review
- system test
- production release
- Resolution Description/checklist

### Performing the Review

In the near term, in-house developer(s) have all the legacy product knowledge as well as design patterns, code constructs, tacit data knowledge, and impacts. This innate knowledge would be key to any code review, including the thought process behind how/why the code was implemented as it is, as well as what this indirectly impacts (which, as we all know, can have far reaching implications).

- Ideally all changes made by anyone, should go through this review process, if for no other reason that knowledge transfer and sharing of legacy learnings and design decisions.
- Very few of these code reviews should take > 5 minutes and could be done on a ZOOM shared screen. (the free version of ZOOM support 2 people for unlimited time, or >2 people for 40 minutes a session)
- FreeConferenceCall provides nearly identical functionality to ZOOM, and is donationware, so free use if you so desire to not donate to supporting the product. They have been in existence for 30+ years.
- If using POP.COM multiple developers can be concurrently working on the same screen at the same time. Cursors each have a floating label indicating the user.
- All code to be modified should have a copy made in a code-WIP folder, code review may be required in the root cause analysis with a repair vector decided
- Once changes are made, move to a CODE REVIEW folder, and schedule a review

#### Prioritization of Efforts

- Severity of the code change impact, will influence the degree of inspection the code requires. Any Sev4 change, can be released without review. Sev3 should require at least a cursory review, and Sev1 and 2, are critical priority actions.
- Note: Severity criteria may be reviewed and changed to meet the environment, and assist in bug classification.
- Once changes are made in line with purpose and objectives, the code needs at least 2 people to review the changes and validate the chosen repair prior to release to production.
- Changes that CRUD (Create, Update or Delete) production data should either be tested against a non-production dataset, or have a plan for immediate roll back of changed data if a problem ensues.
- A checklist of change impacts should be completed for every change - code, TO, fields, calcs, presentation objects, layouts, etc, with the option to add a note to the checked item.
- As the currently solution in in 4 business unit code bases, knowing what elements were impacted so that configuration management of these other instances has a checklist to work against.

### Bug Tracking

Many current environments collect trouble tickets through a generic email message, without structure or process. Often, the description in insufficient to understand the problem, and requires the developer to contact the user for more information.

Moving to a formal bug-tracking approach, automates a large amount of the effort that developers need to do to discover the real problem.

In addition to these few items entered by the user, the following information is collected automatically, and entered into the bug report:

- The user and account name (they may not be the same)
- The IP (dynamic) and NIC (static) address of the computer where the bug is being reported from
- The version of which operating system they are currently using
- The version of FileMaker™ they are currently using
- The server that this is running from
- The privilege set (authentication level) that they are operating under
- The program/solution file they are currently running
- The layout the user is currently on
- The data table occurrence context
- Which solution / product is the report coming from
- A timestamp of the reported issue
- A default severity of 5 - the status prior to any root cause analysis

..... And most importantly, a snapshot link of where they are in the data at this moment.

This SnapShot Link allows the developer to click the link, and be taken directly to the program, on the layout the user was on, with the found set of data the user was currently viewing when the bug was reported.

### Naming Conventions

There are multiple areas where consistent naming conventions improve understanding, readability, and productivity. There are no standards for this - it is all developer organizational preferences. However, there is sound rationale for the naming conventions described in this document.

### Code Notations

The following comment indicators within scripts should be used in order to consistently represent code content, AND provide a method of quickly finding code review items. A DDR – Database Design Report – generated from FileMaker can be quickly searched for content, allowing changes to be discovered and reviewed.

# #################################  Comment Block

# ---------------------------------  Sub-Functional Visual Break

# =================================  Major Functional Change Break

# xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx  End of Code

# ?????????????????????????????????  Indicator of Code Review Question

# *********************************  Alternative Approach Block

# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  Concern over code content

Recent addition: # TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT

Is used for TEST code. Note that using each of these comment types allows easily findable code sections.

### Comment Block Details

The top of each script (named code element), should contain a consistent set of information as defined below, in order to maintain shared understanding, as well as “future self” being able to recall and understand what “current self” did in the code and when.

This is one aspect of the manual efforts to overcome a significant FileMaker development deficiency in configuration management of code.

# #################################

# Performs <functional abstract description>

# Created on: <date created>

# Created by: <developer name>

# Last Modified: <date modified>

# Modified by: <developer name>

# #################################

# <Change Description abstract>

# <Change Description abstract>

# <Change Description abstract>

# <Change Description abstract>

# #################################


The following code comments can be used to assist in code reviews, allowing for the rapid discovery of the code changes to be reviewed or questions answered.


# ?????????????????????????????????  Indicator of Code Review Question

# *********************************  Alternative Approach Block

# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  Concern over code content

Recent addition: # TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT


Is used for TEST code. Note that using each of these comment types allows easily findable code sections.

### Naming Conventions Detail

- Naming conventions are a critical piece to developer productivity
- Everyone has their own preferences
- Agreement on naming conventions improves productivity and quality, and reduces errors and rework
- Areas where naming conventions are useful:
- Field names/categorizations
- Table names - sort order and unique distinction
- Table Occurrence Names - meta data about relationship conditions
- Script Names - functional understanding
- Global Variable Names - for readability
- Local Variable Names - for design pattern recognition
- Layout Names - layout navigation where layout names have user recognition, simplifying code
- Value List Names - purpose definition for automation

Folder names for organization of layouts and scripts And Script Comments / Structure inside code. The terminology, **TIP**s, **TRICK**s and **TRAP**s for each of these, is contained in the following document.

## FileMaker™ Naming Conventions / Design Patterns Guidelines Overview and Rationale

Naming conventions are a useful tool to development activities, as it aids in consistent understanding of various elements within the development process. Future self will praise “current self” when one goes back to make changes in the historical product, where there is logic in how things are defined.

Design patterns are constructs in the organization of code content and object structure, that provides a consistent, performant approach to performing tasks in the most efficient, and reusable fashion.

#### Definitions

- TABLES - the named source data for a set of fields
- Table Occurrences, aka TOs - an alias to a table, used to build discrete relationships between other TOs
- Table Occurrence Groups, aka TOGs - a group of related TOs that provide a discrete set of functions, often used specifically for a layout context and the related TOs making up the group.
- Brittle - a term for elements of coding that can be inadvertently “broken” by actions elsewhere in the program.
- This is a problem to avoid through the prudent use of indirection. As FileMaker™ stored EVERY object within the system with its own unique, never to be reused ever, ID number, FileMaker™ manages much of this automatically. However, as you get into more advanced approaches, particularly around reducing code complexity or verbosity, indirection will become more prevalent.

Cardinal Rules (failure to do follow these cardinal rules will likely result in errors and a lot of work-around efforts) :

- No spaces in names
- No leading punctuation or special characters (to avoid escaping characters to support other languages like SQL)
- Pick a naming technique and stick with it. CamelCase or underscores_as_spaces preferred
- Decide on singular or plural in names and stick with it.

## Tables

### Source Tables

All Source Tables shall be all UPPER CASE with a leading z and an underscore (e.g. z_CLIENT).

- **TIP**: The z_ concept makes all source tables appear at the BOTTOM of selection lists, and segregated from any other table occurrences in the relationship graph. Upper case is to be uniform across all TO’s for visual identification of SOURCE table, within the TO name.
- **TRAP**: Source tables are never to be referred to on layouts, scripts or calculations, with the exception of from the context independent SQL commands

### Table Occurrences

FileMaker’s Table occurrences (TO), in the world of databases, are unique construct. A TO is an alias to an actual source table, and as many as needed can be added to a relationship diagram. Relationships established between these TO’s - collectively called a table occurrence group - are, in effect, hard coded queries.

Table occurrence names should be structured with sufficient intelligence to discern the relationship structure and relationship basis from the name itself. This speeds up development in selecting the correct TO for the field display required. The parent table is always referenced from the reading left to right through the TO name. The source table in any TO name shall be UPPER case. Relationships will be reflected in the naming by a tilde (~) after the parent To name, the relationship itself (typically id) and a tilde followed by the source table name in upper case. The name can optionally have a suffix indicating the sort order.

- e.g. parent~id~CHILD|sDatePaid

In addition, each TO shall be named with an agreed to N digit prefix – 5 in this example.

- The first digit is the TO group, typically T, but may also be U (utility) or z (base tables)
- The next digit is a 2 digit numerical designation for a given table occurrence GROUP (see next section).
- The last, is a sequential alpha character designating the level from the anchor. The anchor TO will have an "a", all child TOs on level down, will have a "b", grandchildren as “c”, and so forth.
- After the prefix, an underscore, followed by the TO name, where the source table of the TO is all upper case letters.
- The UPPER CASE text, refers to the source table that this TO is a alias to.
- The ~ID~ (or other connection term), loosely defines how the TOs are related.

Example of a 2 TO parent-child relationship name

- T01a_INVENTORY
- T01b_inventory~ID~SKUS
- This allows both sorted groups of TOs within a list of TOs, and understanding of where it is in the TO hierarchy within that group, a key element to placement of related fields on layouts and referencing within scripts.

### Table Occurrence Groups

- There are typically 3 major groupings of table occurrence groups (TOG), ideally in anchor-buoy approach.
- A basic data structure depicted in a relationship diagram of primary<>foreign keys. This is NOT used in any user interaction, but is for utility actions on the part of the developer. This may be more of a spider web model than anchor buoy, as it's purpose is solely to define core data relationships.
- **TIP**: Doing this is very effective, IF you plan on creating a segregation model, with presentation/logic, in a different file than data. This TOG defines the data explicitly.
- A data structure for presentation (TOG) - the view model of the application, This can be where all relationships are defined that impact presentation in the view model part of the solution.
- A data structure for edits and reports. These have relationships (TOGs) defined that lend themselves to presenting the right subset of data for user input.
- A data structure for selection Go To Related Record (GTRR) functions. This will be described later.

### Field Names

Overview - this structure, with names in alphabetical order, produce a clear picture of usage.

a underscore underscore prefix is an ID for relationships the same in every table


any field starting with Z is NOT direct user input,

za_ prefix is an auto-enter (the exception - it may be overridden with user input

zc_ is a calculation

zgm_ is a global used for a matching relationship

zk_ is a constant,

zs_ is a summary field

zsl_ is a summary list field - the 3rd digit identifies the type of summary field

zu_ is a utility field (seldom needed)

zx_ are deprecated fields, but retained until all their usage can be purged from code and layouts


Each of these conditions has a separate for in the data model field list

za_-------------------------------


GLOBALS (except for those required for a relationship match) all exist ONLY in a globals table

g_ is a global


- Field names shall be broken up 3 primary groups; key fields (a__), user data fields (no prefix), and utility fields (z prefixes).
- In the MANAGE DATABASE field screen list, the following dummy fields assist in breaking the field list into manageable pieces, based on the naming conventions defined herein.
- Underscore prefix is an ID for relationships
- any field starting with Z is NOT used for direct user input
- **TIP**: A set of default fields can be defined in a fmdefaults.xml file as a baseline starting point for new tables.
- **TIP**: Recommended practice / guideline: Auto-enter calculation fields should only be used for 4 purposes:
- To set a primary key for a table
- To change the format of the entered contact (e.g. a phone number format)
- To set a default value (e.g. created by, modified when, found count calculation)
- To set a constant value used in a persistent matching relationship
- **TRAP**: Incorporating business logic into field level calculations is problematic, in that there is no programmatic control over point of execution. It is NOT recommended practice.

### Key Fields


##### PRIMARY KEYS

Key fields are prefaced with a "a__". That way they sort to the top of the list while maintaining compatibility with SQL without having to escape characters (names that start with punctuation require addition code to process in SQL).

A primary key will always be named "a__pkid" (or “a__pk”) in EVERY table (except tables comprised entirely of globals.)

This is to support code standardization in grabbing primary key IDs to be used as foreign keys in related records, and modular code constructs that can be used repeatedly. Having the exact same primary key name in every table, provides significant benefit to programming efforts in creating modular, reusable code and indirection benefits.

##### FOREIGN KEYS

Foreign keys shall be named similarly but appended with the source table name. • e.g. "a__fkid_CHILD

- **TRICK**: By setting “create through relationship” to true, any child record will automatically get the primary key of the parent, assigned to the foreign key of the child.
- **TRAP**: The associated result of setting create through relationship to ON, is that a phantom record shows in a portal – a place to do data entry. However, it shows as empty fields at the END of the records in the portal, and if there are more records in the child table than the portal has rows, that record will not show. (See “ghost portal” for a method of solving this).
- **TRAP**: Foreign keys will typically never change; they define a static relationship between the parent and the child table, and as such, are immutable. An exception to this might be when the child records do get re-assigned to a different parent, but that is an uncommon exception.
- **TRAP**: Foreign keys are never dynamically changed temporally. The immutable nature of the primary-foreign key relationship is such that a developer would always consider the relationship to be sacrosanct. Dynamically changing foreign keys should never occur.
- The normal FileMaker construct for a changing relationship, is to set a global field on the parent side of the relationship, to the set of values that you wish to match against the child. This multi-line (not to be confused with multi-predicate – more than one field) construct of a list of items placed in the parent side of a defined relationship, filters the child with the list of related values, matching any one of those values.

#### Data Fields

All user data fields are best named in normal human terms for the particular field. In that way, because they lack the identifying structure of non-user data fields, they can be used directly as field labels. A somewhat subjective naming aspect, however, is to create a name starting with the general and moving to the specific. things like:

- Date_paid
- Date_invoiced
- Date_shipped
- Doing so, groups the fields based on general affinity alignment, making the programmer job easier by quickly getting to the affinity grouped data.

### Utility Fields

- The last section is the most diverse; utility fields. These are fields that are either used internally to control actions, or calculated results that have no user data entry capacity but may have presentation.
- All these fields start with a “z” so as to sort to the bottom of the field list.
- A “z_” is a basic utility field, like z_createdby
- A “zc_” is a calculated field
- A “zg_” is a global field, however, these should almost always be in a globals table, and start with a “g_”
- A “zgm_” is a global field, used for relationship matches and is in the data table
- A “zk_” is a global constant, again, used for relationship matches or even in code (although code uses may also be in global variables, not fields. There are reasons for one vs the other, based on security. A global variable in memory is more susceptible to hacking than the safeguards that can be placed on a global field, so sensitive data may be better off in a field than a variable.
- A “zs_” is a summary calculation field, and often contains a 3rd digit to indicate list, count, sum, average, etc.
- A” zx_” prefix is a deprecated field, that may, once investigated, be deleted from the solution.
- Field options - Stored vs Unstored calculations
- Stored calculations are contextually ALWAYS within a single table. That is necessary, as there is no mechanism for a change of data in another table to be reflected in a STORED value through calculations. To accomplish the creation of a stored value, requires other methods, like scripted actions. You are not allowed to set a calculation that technically cannot be stored, as a stored calc. Any reference across relationships, referencing globals or unstored calc fields in the calculation will force an unstored calc condition.

### Unstored calculations:

Unstored calculations have value. They allow dynamic changes to occur automatically based on data changes in other places within the program.

- Conditional formatting - typically color coding of information to convey to the user, some status
- HIDE conditions - inverse logic conditional formatting, resulting in hidden objects given certain conditions, such as privilege set, or changing data.
- A summary field - (more on this later) a set of defined calculations that can summarize the current found set within a given TO. This feature provides tremendous power in reporting, and typically, the result is well worth the relatively minimal performance penalty
- A field option calc, where the calc contains predicate data that contains a 1) global, 2) from an unstored calc 3) uses a field from a related table.

This last unstored calc is the typical performance bottleneck. This option is often used as it is easy to implement, consistently provides the expected result without additional code work, and, if used judiciously, produces little performance impact. However ........

- **TRAP**: Unstored calcs in a list view are performance costly; they have to be evaluated with every record displayed that shows the unstored calc in the list. The more complex the calculation, the greater the performance hit. Unstored calculations have to be evaluated EVERY time and for EVERY record that is being displayed. As a result, this can be a massive performance hit.
- **TIP**: Unstored calcs can be very useful, AND if used in FORM (single record) view - because they only calculate when displayed and are only calculating for the one displayed record - are light on computing resources.
- **TRAP**: Unstored Calcs cannot be indexed, therefore cannot be used in the child side of a relationship.
- **TIP**: Note that a stored value WILL change, if a predicate value changes, but only within the context of that table.
- **TRAP**: Even within the limited scope of a single table, IF the calculation references a global, or an unstored calculation, the resultant calculation will be forced to change to an unstored calculation.
- **TRAP**: FINDS against unstored calcs are costly; each record touched, gets its' unstored calcs reevaluated one at a time, to determine if the result is within the FIND parameters.
- **TIP**: Use unstored calcs on list views/portals sparingly if at all. Replace with coded data updates, if possible (and feasible effort). Only display unstored calcs in form view, where only one record will be displayed.
- **TRICK**: Script triggers can be effectively used to write data to fields that are a common usage of an unstored calc.
- **TRAP**: Unstored calcs are often used to deformalize data for presentation and constraints on FINDs.
- For instance, IF the related child field is on a layout, based on the parent, this fields presents the data from the first related record from the child table (controlled by relationship sorts).
- IF a user does a FIND on that child field, the relationship is ignored; it searches all the child records, and returns values that may not be part of the expected result, when that result only wanted to search for the first related field content.
- In that case, the typical process would be to place an unstored calc in the parent table, pulling the most recent field data from the first child record - resolving the FIND issue - but at a significant performance cost.

There are design patterns that can avoid this issue and should be considered always. One method is shown in the next section on the concept of auto-enter calcs.

### Auto-enter calc vs calculated fields:

Auto-enter calcs are calculated completion of field content, at the time of record creation, and performed automatically. Unlike a calculated field (stored or unstored) a user can be allowed to change that value, overriding the calculated content.

- **TIP**: Replacing unstored calcs with performant auto-enter calcs, can be done, following these rules:
- resetting a parent field that is used in a relationship, to itself, forces auto-enter calcs to update, assuming the calculation is pulling data from a related table based on that relationship.
- An auto-enter calc will trigger with any change of dependency to that calculation. So judicious coding of calculation elements in the auto-enter calc, can force an update, creating static content.
- **TIP**: Calculated fields are NOT editable (browsable). Auto-Enter calculations can be made browsable, and therefore, user editable. This is useful for default data content.
- **TRAP**: So that future self will not curse at current self, missing where data changes occur, vs where presentation changes occur, can prove problematic.
- **TIP**: GENERAL Rule of thumb; It is best that NO data content changes occur in an auto-enter calc; all those changes are done in code, or from user edits. Auto-enters should be for either 1) default data entry or 2) reformatting user input at the presentation layer. e.g. take a phone numbers, and reformat it in a standard format uniformly, regardless of user input. This is a very difficult
- **TIP** to conform to, as auto-enter calcs have many other uses.

### Resolving performance: Conversion of unstored calcs to stored values

- In a field level calculation, if you use a LET (setting a variable within a calculation) you can set a variable that has nothing to do with the resultant calculation outcome, but setting that variable from say, a reset timestamp field, would force the calculation to re-execute, updating the content, but without the performance impact of an unstored calc.
- By adding a timestamp field to every table, named "z_Trigger_TimeStamp", an OnRecordCommit script can set this value to Get (CurrentHostTimeStamp) forcing whatever the calculation is, to evaluate. This is common for things like denormalizing data from related tables, or days till due calculations.

Let (

[

~ts = z_Trigger_TimeStamp ;

~today = GetAsDate (~ts) ;

~remaining  = ~today - Date ( 12 ; 31 ; Year ( ~today ))

]

;

~remaining

)


/* Calculation only trigers when z_Trigger_TimeStamp  is set - TBD @ Commit */


### Validation – Improving the UX

There are some aspects of the field level validation provided in FM field options, that are situationally effective. However, this is the exception not the rule, at least for more advanced solution deployments.

- TRAP: post entry validation ("Nagware") in not user friendly. Telling the user after the fact with some cryptic, context insensitive, unidentifiable error message, generically defined by FileMaker, that they made a mistake - although gratifying to the programmer - is not good customer practice. Avoid field level validation in field options, **TRAP** the error, and provide a more eloquent user feedback. Even better would be to proactively implement techniques to limit input to valid content.
- **TIP**: Validation of data is essential. The best way is to take all steps to ensure that user data entry will be appropriate at data entry time, like with value lists, or UI selections that fill in fields automatically. IF post entry validation is required, it is often best to code it as data entry time with a more user understandable custom dialog, rather than the cryptic one that FM provides. You can also validate a bunch of fields in code, returning a list of what needs to be fixed to the user, which is far more effective than general purpose "nagware".

### Global Field Usage in FileMaker™

#### (the 10 points are attributed to Dr. Ray Cologon)

- A global calc will update automatically if it references a global field that is located in the same table and that field is edited by the current user.
- A global calc will update automatically if it references a regular field that is located in the same table (and referenced directly) when that field is edited on any record by the current user. In this instance, the value of the global calc will depend on the value of the referenced field in the record in which that field has most recently been edited. When the global calc references mul**TIP**les regular fields, its value will depend on the values in the instances of those fields located on the particular record where the most recently edited (by the current user) of any of those fields resides.
- A global calc will NOT update if it references a global field that is located in another table, if that field is edited by the current user.
- A global calc will NOT update if it references a global field (in the same table and referenced directly, or in another table) that is edited by different user (users see their own separate global values...).
- A global calc will NOT update automatically if it references a regular field that is located in the same table (and referenced directly) when that field is edited on any record by another user.
- A global calc will NOT update automatically if it references a regular field that is located in a related table (even if a self-relation) if that field is edited on any record by the current user or by another user.
- If a global calc references one or more related fields (as per 3 and 6 above) and ALSO directly references a local field, either global or regular, the value of the global calc will depend on the related values which are current (for the current user) at the time when the local (to the table in which the global calc resides) value/s are edited.
- The value of a global calc when a solution is opened remotely will be the value that it had on the host when last closed (sound familiar?!).
- The values of global calcs in a hosted solution can be 'tickled' at login by changing a local field which they reference. Eg if there are several dozen global calcs with formulae constructed along the lines of:

If ( not IsEmpty(GlobalsTable::RegularTriggerField); RelatedTable::dataField)


then they will all update to reflect the current (related) values at start-up if the start-up script includes the command:


Set Field [GlobalsTable::RegularTriggerField; "1"]


- Changes made to referenced regular fields on another workstation will not appear in global calc results until a refresh event (eg as per 9 above) has occurred on the current workstation - eg the next time the start-up script runs. If there is no triggering mechanism (as per point 9) then the changes will not appear at all until the solution is taken offline, updated in a client session, closed and reopened on the server, as is the case with non-calc globals.As usual, you can take information like this from Dr. Ray to the bank.

===============

As global fields are accessible anyplace with the file, if they are NOT used in relationships, they should be stored in a _GLOBAL table, and be prefaced with a “g_”.

The exception where the global are NOT to be stored in a single GLOBALS table: The global is used for the parent side of a relationship match. These field names start with a “zgm_” (match) or “zgk_” (constant)

- **TIP**: Global persist for the duration of user session and not beyond. The one exception is global fields set in a solution prior to it being hosted, are retained as defaults in the hosted file.
- **TRAP**: Global fields as per user, per session; Perform-Script-On-Server is run by FileMaker Script Engine (FMSE) which is a new session with no knowledge of the globals set before initiating the PSoS action.
- **TIP**: Global variables are accessible across multi-file solutions
- **TRAP**: global fields are only visible to the file they reside it. (needs confirmation)

### Summary vs Commands that perform the Same Function

Summary fields all have a corresponding script step. Although they perform the same function, they have a different context and differing application. Both options are unstored calculations.

The graphic displays a list of options in a summary calculation field.

- The key difference between summary fields, and the corresponding script commands is one of context: a summary field works within the context of a single table, against the current found set of that TO.
- A corresponding script command works across a relationship, on the found set of the child table, based on the relationship query or FIND the produces the child data found set.
- Summary fields are very useful in sub-summary reports, as they work on the found set of a sub- summary section as well. This means that one sub-summary field can be used in multiple sub- summary sections, calculating for the groups created as a result of the sub-summary sort/group condition.

## Layouts and their Names

A good practice in layout names to use what the user would expect the screen/layout to be named. That way, in your code, you can provide user navigation to layouts just based on the name itself from a value list, and reduce code requirements by Go To Layout (calculation/name) rather than something more complex, or requiring defining the layout name in code. For instance, a value list can contain the names of a group of reports, and those report names coincide with the layout names, the user and the code needs are met in one effort.

### User Layouts

- **TIP**: Indirection. The script command, “GetLayoutNames” returns a list of layout names; the script command, “GetLayoutIDs” returns a list of layout IDs, in the same order as the layout names. By placing both into respective variables, one can incrementally loop through the layout names, and return the incremental number matching the name of the user selected layout to navigate to. A GetValue (list of layout IDs ; TheReturnedValue), will return the immutable LayoutID #, which can be used by a Go To Layout (Calculation by number), and therefore, is not “brittle”.

### Utility Layouts

- **TIP**: Layouts that are never to be seen by a user (utility layouts), should have some distinctive naming prefix so that you can programmatically eliminate those layouts from the layout selection in navigation or be quickly recognized in coding efforts.

When troubleshooting, having a layout that is in table view provides data insights that are of great value. This layout is likely the opposite of the blank, containing many fields and rows of data. This layout is NOT a good place to navigate through as part of general program operations, due to performance impacts (as well as never giving an end user access to a table view of the data!).

- **TRAP**: As context is king in FileMaker, a number of layouts are created solely for the purpose of being able to select a particular context. When updating data in a table, switching to a layout in that context is required. BUT that layout has to load those records, taking time, so.............

#### BLANK Layouts

Blank layouts serve a purpose, in that you can do to a layout with no data fields, and perform actions on the data in the associated table. The advantage is with no data to display, it improves performance.

- **TIP**: use a blank layout. There is no requirement for fields to exist on a layout to update, find or sort them. This layout is often based on a TO with no relationships, but that is just a general rule of thumb. This layout's TO - never to be seen by a user - is often based on the core data model TOG, so that normally related fields can also be picked up.

This same layout is also the one that might be the most appropriate for exporting data.

SO, these layouts might be named "blank_CLIENT" or "util_CLIENT" to reflect the purpose, but NOT a name that one would use for showing to an end user.

### SCRIPTS

#### Script Names

Action-Object (Verb-Noun) plus indicator of parameter. Script names are searchable in FileMaker, so a name that had meaning is valuable.

Script Folder Organization

Folder names should reflect an organization hierarchy that facilitates the ease of finding the script by name.

Group by TOG name - as almost all scripts run within the context of a Table Occurrence Group, the TOG group identifier should be a key hierarchical element.

### • Cross-Application ⁃ Navigation

#### ⁃ Menus

⁃ Shared_Common

- Application
- Startup
- Shutdown
- Table Occurrence Group Name

⁃ Layouts [Name of folder matches Layout Name]

- ⁃  Shared_Common Across TOG
- ⁃  User Interface
- ⁃  Business Logic

### Presentation (UI)

#### Styles

FM, starting with version 14, makes extensive use of styles to presenting information, all stored in CSS. CSS loads quickly, making rendering of screens relatively quick.

- **TRAP**: Manually setting formatting conditions that are NOT stored in styles, cumulatively, can be a performance hit as each object format change modifies the CSS used to render the layout.
- FLAG: There are over 24,000 overriden CSS styles in the current product.
- **TRAP**: The default style from pre-14 versions of FM, will NOT render correctly in WebDirect and has performance implications in FM. If you are using that style sheet, conversion is highly recommended. Tony White Designs has an online procedure for quickly making the conversion.
- **TRAP**: Defining styles, applying them, then changing them, can have far reaching implications. Once a style is saved into a theme, every place that style is used within that FM solution, will change accordingly.

#### Styles Naming

This is very much a personal preference. I dislike style names that are descriptive of the function (header, footer, body). Instead, I personally prefer a style name that emulates the defined format of the resultant object from that style. That way, style names are format based, not based on a function.

Additional work needs to be done to codify that concept, but in general, it would look something like this.

- **TRICK**: Instead of "heading", it would be 18ptBld_LJ_noBG_noLN describing the style as 18 point, bold text, with no background and no lines.
- **TIP**: PerformanceBTS has built a FM solution to assist with setting style names. You select the characteristics, and it builds the file name to use. You can then paste it in to your solution.

#### Themes

Collectively, styles are stored in a theme, and that theme is portable between solutions.

#### Button Bars

One of the biggest UI enhancements of recent FileMaker™ enhancements, button bars are exceedingly flexible UI elements.

Note: I no longer use buttons anyplace; it is always a button bar, even if it is one segment bar. This is because of the flexibility of button bars.

#### Button bar labels

Segment labels have the full power of the calc engine; anything you can do in a calculation, you can use for a label in the button bar segment. This means that live data fields, calculated results, concatenated items, multi-line items, variables, both local and global, etc. can all be in a button bar segment label.

*Why would you want/need that? *

Inserts of FM symbols, like {{ RecordNumber) }} in a list, takes a lot of space. The typical format, everything between the braces really small, is a poor work-around. Placing the calc in a button bar segment affords not only a cleaner layout mode presentation, but the button itself can contain additional intelligence, like an icon, and a popover, and record information, etc.

A button bar segment can contain a field. The button is functional, and can perform an action based on clicking the apparent "field", including a popover. This provides script control of field content edits as the button label itself is not directly editable in browse mode.

Button bars as menus: Segments can be queried as to content (once the segment has an object name). SO, if you were to use a set of variables, fields, or repeating fields, to populate segment labels, when you click on that segment, it can act on the content of that dynamic label value.

Button bars as status/dashboard: with a calc, a button bar segment can reflect live data and static labels, with an icon, so makes for a very pleasing dashboard display.

- **TRAP**: Button bars are a fixed length, so hiding a segment, makes the other segments wider, an unpleasant UI anomaly.
- **TRICK**: IF a segment has a hide condition, place another segment in the button bar, with the opposite hide condition. That way, the # of segments in a button bar remain constant, and the size does not change.
- **TRICK**: Getting a button bar to return the content of the button, has always been a painful exercise, having to name the object then user hard coded content in a GetLayoutObjectAttribute command. Not fun. This obscure
- **TRICK** was recently uncovered. IF you use a combination of conditional formatting (which is evaluated early in the execution cycle) and a LET command (which is also evaluated early in the cycle), you can effectively return the value in a button bar segment with little coding effort.
- The conditional formatting syntax is Let ( $$Name = self ; 1 )
- Once set, clicking the button returns the content of the button label to the $$name variable

### Button Bar FAIL condition

- **TRAP**: A Get (RecordID) (and a number of GET commands that return a number) as a calc in a button bar segment, when placed on a portal row, does NOT return the portal row number. This is the one place I have found where a button bar calc does NOT work correctly.
- **TRICK**: In this case, you have to revert to the old school approach of a {{RecordNumber}} on the portal row.

#### Button Bar States

- **TRAP**: a button bar, once clicked, retains the active state for that segment selected. This means that if you want to click it again without clicking off the segment, it won't allow it. Also, if the button bar segment is in a list/portal, any visual state change will impact every record, which is very visually disconcerting.
- **TRICK**: In those cases, set the specified calculation in the button bar dialog, to "1" (any value that would never be true, would work). That way, the selected segment will highlight only for the current record, but also, because the segment is effectively NOT selected, you can click on it a second time (useful for button segments used for column sorting).

### Conditional formatting

- **TRAP**: setting segment colors in the inspector, formats all segments uniformly. You can avoid conditional formatting if all segments color the same for the same state.
- **TRICK**: IF you use a placeholder button bar segment, and there are icons in the segments, conditional formatting will make a cleaner presentation. Just set the segment conditional formatting formula to "true" and format the icon as transparent.
- Button bars conditional formatting works for all segments from the setting of one, WITH THE NOTABLE EXCEPTION above - the formula of "true". In this case, you can, for instance, create a button bar with different colors for each segment.

### Layouts

Use the minimum set of data per any layout. The current trend is for a “single-pane-of-glass” approach. One window as a viewer of data, and a card window to support edits, limited to the scope of the edited record(s).

### Portals Types and Portal Constraints

FileMaker™ introduced List-Detail (formerly known as Master-Detail) portals in version 17. The new portal type has distinct attributes that vary greatly from the traditional portal paradigm.

A List-Detail portal is based on the same TO as the layout itself. None of the traditional methods of dealing with selective data in a portal apply; everything in this type of portal is controlled by the found set of the base layout context. This brings great power to the ability to present and access data with far less work. BUT it also brings limitations, explicitly around the concept of related data, which is only appropriately displayed in a traditional portal.

Traditional portals have their own set of limitations:

- sorting is both slow and complex to implement
- Relationships are required to populate portals
- Portal **filters** are not performant on large record counts. Relationship filters are far more performant, but require relationships to be established in order to correctly filter portal data. A filtered portal has to load all related records prior to executing the filter, whereas a relationship filter, reduces the found count prior to updating the portal content.

## General Development Guidelines

A model, where a main screen presents the data, and all edits are done with an overview window, typically a card window, is a very effective model. The layout and code segregation works very well in this model. This is a simplistic version of the model-view-controller model common in web development.

- **TRAP**: Starting with a card window presentation during development, is fraught with issues. As the card window is modal to the parent, there is no way to enter layout mode to make changes during development.
- **TRICK**: Make a conditional branch setup for a document window and a card window, with a hard coded variable to force the selection. Then, during development, the card will be suppressed, but can be turned back on with a code switch.

### Web Viewer Development Implications

- **TRAP**: A popover will not open over a web viewer
- **TRICK**: Hide the web viewer in the script trigger associated with the opening/closing of the popover

### Container Field Implications

- **TRAP**: A popover will not open over a Container field in Windows
- **TRICK**: Hide the web viewer in the script trigger associated with the opening/closing of the popover
- **TRAP**: PDF documents are not all created equally.
- **TRICK**: provide 2 views, one as a graphic container (no scrolling available) and one as an interactive PDF. The graphic will always display, and if the PDF is able to be rendered, it too will display in say, another tab.
- **TRICK**: there is a way to display a PDF in a web viewer that is more generic in nature, and works more often but is tougher to implement. It uses Base64 encoding and some simple scripting.

Update: With the advent of FileMaker 19.3, Microsoft Edge is the default PDF rendering engine on Windows. This has brought some changes in interacting with PDFs, mostly for the better.

### Web Direct Development Implications

Almost everything works without issue from web Direct (WebD). There are a number of advantages to Web Direct as well. In particular, as Web Direct executes completely on the server, resulting in exceptional performance. There are no record data load times over the net and only the screen content is being transmitted. Performance is typically outstanding, IF you have sufficient server resources to power it.

- **TRAP**: The editing of value lists within value lists (the optional selection of EDIT or OTHER in the inspector for a drop down or popup value list presentation) is not available in WebD.

Code Deployment - How to manage production/dev servers vs live code changes

Note: OTTOFMS and OTTODEPLOY are key elements in making this work effectively.


# The End

- –––––––––––––––––––––––––––––––––––––––––––––

## Version: Revision R9

## Last Edit Date: 12/8/2025 Prepared by: Kirk Rheinlander

## –––––––––––––––––––––––––––––––––––––––––
